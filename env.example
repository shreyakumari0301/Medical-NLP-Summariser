# OpenAI (default, requires paid API)
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-3.5-turbo

# Ollama (FREE - runs locally, install Ollama first)
# USE_OLLAMA=true
# OLLAMA_MODEL=llama3.2
# OLLAMA_BASE_URL=http://localhost:11434

# Groq (FREE tier available - fast GPU inference)
# Valid models: llama-3.1-8b-instant, llama-3.1-70b-versatile, gemma-7b-it, llama-3.2-3b-instruct
# Note: mixtral-8x7b-32768 has been decommissioned
# USE_GROQ=true
# GROQ_API_KEY=your-groq-api-key
# GROQ_MODEL=llama-3.1-8b-instant

# Frontend Backend URL
NEXT_PUBLIC_BACKEND_URL=http://localhost:8000

